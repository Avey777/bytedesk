# 网站整站抓取功能说明

## 功能概述

网站整站抓取功能允许您从指定的网站根域名开始，按照设定的抓取深度和规则，批量抓取整个网站或网站特定部分的内容到知识库中。

## 核心特性

### 1. 多层级抓取

- 支持1-5层的网站深度抓取，可控制抓取范围
- 从根URL开始，逐层发现并抓取链接

### 2. 智能链接发现

- 自动发现和跟踪网站内部链接
- 支持相对链接和绝对链接解析
- 过滤外部链接，只抓取同域名内容

### 3. 批量内容处理

- 高效处理大量页面，支持并发抓取
- 可配置并发线程数（1-10个线程）
- 智能延迟控制，避免对目标网站造成压力

### 4. 去重机制

- 自动识别和过滤重复URL
- 内容有效性验证，过滤无效页面
- 智能检测404、403等错误页面

### 5. 断点续传

- 支持大型抓取任务的中断恢复
- 任务状态持久化存储
- 失败重试机制

### 6. 站点地图支持

- 可基于sitemap.xml进行更精准的抓取
- 自动发现常见sitemap路径
- 提高抓取效率和完整性

## 使用场景

### 官网文档批量导入

一次性抓取整个产品文档站点，如技术文档、API文档等。

### 知识库迁移

从旧的文档系统批量迁移到新的知识库系统。

### 竞品分析

系统性地抓取竞争对手的公开信息和产品文档。

### 内容同步

定期同步外部知识库或文档站点的最新内容。

## API接口说明

### 1. 开始整站抓取

**POST** `/api/v1/llm/website/crawl/start`

```json
{
  "websiteUid": "网站UID",
  "config": {
    "maxDepth": 3,
    "maxPages": 1000,
    "concurrentThreads": 3,
    "timeout": 10000,
    "delay": 1000,
    "followLinks": true,
    "useSitemap": true,
    "includePatterns": ["/docs/.*"],
    "excludePatterns": ["/admin/.*", "/private/.*"],
    "minContentLength": 50
  }
}
```

### 2. 快速抓取

**POST** `/api/v1/llm/website/crawl/start/fast`

使用预设的快速配置（较少页面和深度）。

### 3. 深度抓取

**POST** `/api/v1/llm/website/crawl/start/deep`

使用预设的深度配置（更多页面和深度）。

### 4. 停止抓取

**POST** `/api/v1/llm/website/crawl/stop`

停止正在运行的抓取任务。

### 5. 查看抓取任务列表

**GET** `/api/v1/llm/website/crawl/tasks/{websiteUid}`

获取指定网站的所有抓取任务历史。

### 6. 查看任务状态

**GET** `/api/v1/llm/website/crawl/task/status/{taskId}`

获取指定任务的实时状态和进度。

## 抓取配置详解

### 基础配置

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| maxDepth | int | 3 | 抓取深度（1-5层） |
| maxPages | int | 1000 | 最大抓取页面数 |
| concurrentThreads | int | 3 | 并发线程数（1-10） |
| timeout | int | 10000 | 请求超时时间（毫秒） |
| delay | int | 1000 | 请求间隔延迟（毫秒） |

### 高级配置

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| followLinks | boolean | true | 是否跟随链接 |
| useSitemap | boolean | true | 是否使用sitemap |
| includePatterns | List | null | 包含的URL模式（正则） |
| excludePatterns | List | null | 排除的URL模式（正则） |
| minContentLength | int | 50 | 最小内容长度 |
| deduplication | boolean | true | 是否去重 |
| resumable | boolean | true | 是否支持断点续传 |

### 预设配置

#### 快速配置（Fast）

- 抓取深度：2层
- 最大页面数：100
- 并发线程：2个
- 请求延迟：500毫秒

#### 默认配置（Default）

- 抓取深度：3层
- 最大页面数：1000
- 并发线程：3个
- 请求延迟：1000毫秒

#### 深度配置（Deep）

- 抓取深度：5层
- 最大页面数：5000
- 并发线程：5个
- 请求延迟：2000毫秒

## 最佳实践

### 1. 配置优化

- 根据目标网站大小选择合适的配置
- 调整并发数避免对目标网站造成过大压力
- 使用URL模式过滤减少无效抓取

### 2. 性能优化

- 优先使用sitemap进行抓取
- 设置合理的延迟时间
- 定期清理无效任务

### 3. 内容质量

- 设置合适的最小内容长度
- 使用排除模式过滤无关页面
- 定期检查抓取结果质量

## 注意事项

1. **合法合规**：确保抓取行为符合目标网站的robots.txt和使用条款
2. **性能影响**：大量并发抓取可能对目标网站造成压力，请合理设置参数
3. **存储空间**：大量页面抓取会占用较多存储空间，请注意监控
4. **网络稳定**：长时间抓取任务需要稳定的网络环境
5. **权限控制**：某些页面可能需要登录或特殊权限才能访问

## 错误处理

系统会自动处理以下错误情况：

- 网络超时
- 404/403等HTTP错误
- 内容解析失败
- 并发限制

抓取失败的页面会被记录，不会影响其他页面的正常抓取。

## 监控和维护

建议定期：

- 查看抓取任务执行情况
- 清理过期的抓取任务
- 监控存储空间使用情况
- 检查抓取内容质量
