<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Bytedesk Blog</title>
        <link>https://www.weiyuai.cn/docs/zh-CN/blog</link>
        <description>Bytedesk Blog</description>
        <lastBuildDate>Fri, 20 Jun 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-CN</language>
        <item>
            <title><![CDATA[MCP在微语系统中的应用]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/mcp</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/mcp</guid>
            <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[解读模型上下文协议的本质]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="解读模型上下文协议的本质">解读模型上下文协议的本质<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E8%A7%A3%E8%AF%BB%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%9C%AC%E8%B4%A8" class="hash-link" aria-label="解读模型上下文协议的本质的直接链接" title="解读模型上下文协议的本质的直接链接">​</a></h2>
<p>在当今数字化转型浪潮中，模型上下文协议（Model Context Protocol，简称MCP）作为一种创新型通信标准，正在重新定义AI系统与企业环境的交互方式。这一协议不仅仅是简单的接口规范，而是构建了一座从"智能对话"到"智能执行"的桥梁，让AI突破了单纯文字应答的局限，转而成为能够感知情境、调用资源、获取专业知识并执行具体业务操作的企业级助手。</p>
<p>与常见的技术架构不同，MCP并非独立的大规模语言模型，而是一种精心设计的"智能中枢"，专注于协调AI模型与企业核心系统（如专业知识库、工单管理平台、客户服务系统等）之间的信息流转。在我们开发的智能服务生态中，这一协议充当了连接不同技术孤岛的神经中枢，让AI真正参与到企业的业务流程与决策体系中。</p>
<p>随着生成式AI技术的迅猛发展，各类大模型如雨后春笋般涌现，其能力范围不断突破想象边界。然而，企业在实际落地这些先进技术时，依然面临诸多难以逾越的壁垒：</p>
<ul>
<li>业务语境的精准理解：如何让AI系统准确把握企业特有的业务规则与专业术语？</li>
<li>主动执行能力的缺失：如何突破"对话-回答"的简单模式，让AI能够自主识别需求并采取实质性行动？</li>
</ul>
<p>模型上下文协议的设计初衷，正是为解决这些企业级AI应用的核心痛点，搭建从"理解"到"执行"的全流程解决方案。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="模型上下文协议的实践价值">模型上下文协议的实践价值<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%BB%B7%E5%80%BC" class="hash-link" aria-label="模型上下文协议的实践价值的直接链接" title="模型上下文协议的实践价值的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="重构智能客服体验从被动应答到主动解决">重构智能客服体验：从被动应答到主动解决<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E9%87%8D%E6%9E%84%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E4%BD%93%E9%AA%8C%E4%BB%8E%E8%A2%AB%E5%8A%A8%E5%BA%94%E7%AD%94%E5%88%B0%E4%B8%BB%E5%8A%A8%E8%A7%A3%E5%86%B3" class="hash-link" aria-label="重构智能客服体验：从被动应答到主动解决的直接链接" title="重构智能客服体验：从被动应答到主动解决的直接链接">​</a></h3>
<p>当今企业客服系统中的AI助手普遍存在三大关键性问题：</p>
<ul>
<li>知识局限症：大多数系统仅能从预设的常见问题库（FAQ）中提取固定答案，缺乏根据具体情境动态构建个性化解决方案的能力</li>
<li>系统孤岛困境：即使识别了用户需求，也无法自主调用企业内部系统（如订单管理平台、工单系统）执行后续操作</li>
<li>记忆衰退现象：难以在多轮对话中保持上下文连贯性，导致用户不得不重复描述问题背景</li>
</ul>
<p>通过引入模型上下文协议技术框架，我们的智能客服解决方案实现了质的突破：</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="1-全景式会话记忆机制">1. 全景式会话记忆机制<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#1-%E5%85%A8%E6%99%AF%E5%BC%8F%E4%BC%9A%E8%AF%9D%E8%AE%B0%E5%BF%86%E6%9C%BA%E5%88%B6" class="hash-link" aria-label="1. 全景式会话记忆机制的直接链接" title="1. 全景式会话记忆机制的直接链接">​</a></h4>
<p>该协议创建了一种持久化的上下文理解系统，能够在整个服务过程中捕捉并保留用户的核心意图和关键信息，并根据对话发展智能地确定最佳系统调用路径。这种能力在实际应用中表现为：</p>
<p>客户："我上周五提交的那个网络故障工单处理到哪一步了？"<br>
<!-- -->→ 系统能立即识别这是一个关于历史工单的查询，自动调用工单管理系统，检索该用户的相关记录，并提供准确的处理进度报告。</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="2-智能系统协同网络">2. 智能系统协同网络<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#2-%E6%99%BA%E8%83%BD%E7%B3%BB%E7%BB%9F%E5%8D%8F%E5%90%8C%E7%BD%91%E7%BB%9C" class="hash-link" aria-label="2. 智能系统协同网络的直接链接" title="2. 智能系统协同网络的直接链接">​</a></h4>
<p>我们的协议框架设计了一种高度灵活的系统间通信机制，使客服AI能够根据对话分析结果，同时协调多个企业核心系统（如客户关系管理平台、专业知识库、供应链管理系统等），在单一会话流程中实现"信息获取-专业解析-实际操作"的闭环处理。</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="3-业务操作自动化执行">3. 业务操作自动化执行<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#3-%E4%B8%9A%E5%8A%A1%E6%93%8D%E4%BD%9C%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%A7%E8%A1%8C" class="hash-link" aria-label="3. 业务操作自动化执行的直接链接" title="3. 业务操作自动化执行的直接链接">​</a></h4>
<p>突破了传统AI"只能回答，不能行动"的限制，我们的系统能够在获得授权的情况下，主动执行关键业务流程：如自动生成技术支持工单、更新用户配送信息、记录并分级客户反馈等，将用户需求直接转化为系统行动。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="知识管理革新构建企业专属智能大脑">知识管理革新：构建企业专属智能大脑<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E9%9D%A9%E6%96%B0%E6%9E%84%E5%BB%BA%E4%BC%81%E4%B8%9A%E4%B8%93%E5%B1%9E%E6%99%BA%E8%83%BD%E5%A4%A7%E8%84%91" class="hash-link" aria-label="知识管理革新：构建企业专属智能大脑的直接链接" title="知识管理革新：构建企业专属智能大脑的直接链接">​</a></h3>
<p>当前许多组织已投入大量资源建立了全面的知识资产库，包括专业知识库、标准操作流程文档和员工培训体系，但在AI集成方面仍面临三大核心挑战：</p>
<ul>
<li>结构化知识应用障碍：现有模型难以充分理解和运用企业特有的结构化知识体系</li>
<li>回溯验证困难：生成回答缺乏明确的信息来源标注，难以进行准确性验证</li>
<li>复杂问题处理能力不足：面对多维度、跨领域的专业咨询，系统往往无法提供切中要害的回答</li>
</ul>
<p>我们通过模型上下文协议构建了一套专属的"知识互联"框架，从根本上改变AI系统与企业知识资产之间的互动方式：</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="1-知识精准定位系统">1. 知识精准定位系统<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#1-%E7%9F%A5%E8%AF%86%E7%B2%BE%E5%87%86%E5%AE%9A%E4%BD%8D%E7%B3%BB%E7%BB%9F" class="hash-link" aria-label="1. 知识精准定位系统的直接链接" title="1. 知识精准定位系统的直接链接">​</a></h4>
<p>我们的解决方案摒弃了传统的"撒网式"语义搜索方法，转而采用更为精确的知识导航机制。系统能够智能分析用户问题的专业属性，直接激活最相关的知识模块，比如针对退货政策的疑问会自动调用"售后服务规范解析器"，而技术故障问题则会触发"产品技术文档理解引擎"。</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="2-全透明知识溯源机制">2. 全透明知识溯源机制<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#2-%E5%85%A8%E9%80%8F%E6%98%8E%E7%9F%A5%E8%AF%86%E6%BA%AF%E6%BA%90%E6%9C%BA%E5%88%B6" class="hash-link" aria-label="2. 全透明知识溯源机制的直接链接" title="2. 全透明知识溯源机制的直接链接">​</a></h4>
<p>在我们的框架中，每一条生成的专业回答都会自动附带信息来源标识，包括具体文档链接、政策条款编号或技术文档章节等，使信息接收方（无论是客户还是内部员工）能够快速验证内容准确性并进行必要的深入了解。</p>
<h4 class="anchor anchorWithStickyNavbar_FOGJ" id="3-多维度知识融合平台">3. 多维度知识融合平台<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#3-%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%9F%A5%E8%AF%86%E8%9E%8D%E5%90%88%E5%B9%B3%E5%8F%B0" class="hash-link" aria-label="3. 多维度知识融合平台的直接链接" title="3. 多维度知识融合平台的直接链接">​</a></h4>
<p>我们的系统突破了传统纯文本知识库的局限，实现了对多种信息载体的智能理解，包括结构化数据表、业务流程图、培训视频以及交互式演示等，使AI系统能够从多维度理解和表达复杂的企业专业知识。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="创新实践模型上下文协议的实战案例">创新实践：模型上下文协议的实战案例<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B" class="hash-link" aria-label="创新实践：模型上下文协议的实战案例的直接链接" title="创新实践：模型上下文协议的实战案例的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="案例展示新一代智能客户服务平台">案例展示：新一代智能客户服务平台<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E6%A1%88%E4%BE%8B%E5%B1%95%E7%A4%BA%E6%96%B0%E4%B8%80%E4%BB%A3%E6%99%BA%E8%83%BD%E5%AE%A2%E6%88%B7%E6%9C%8D%E5%8A%A1%E5%B9%B3%E5%8F%B0" class="hash-link" aria-label="案例展示：新一代智能客户服务平台的直接链接" title="案例展示：新一代智能客户服务平台的直接链接">​</a></h3>
<p>在我们为某头部电商平台打造的新一代售后服务体系中，模型上下文协议技术在实际业务场景中展现出卓越价值。以下是一个典型交互案例的流程解析：</p>
<p>当顾客向系统提出："我前天下单的那双运动鞋至今没有物流更新，请问是什么原因？"</p>
<p>系统随即启动一系列智能处理流程：</p>
<ol>
<li>意图精准识别：系统立即将此问题分类为"物流状态异常查询"，而非简单的订单状态查询</li>
<li>多维数据获取：自动调用订单管理系统和物流跟踪平台，获取该用户特定订单的完整信息链</li>
<li>智能情境分析：结合物流数据、仓储情况和历史延迟模式，构建可能的原因分析模型</li>
<li>个性化解决方案：根据实时数据生成详细解释，包含具体延迟原因和预计发货时间</li>
<li>主动推荐选项：根据客户VIP等级和问题紧急程度，提供相应的补偿方案，如优先发货、配送费减免或积分补偿等</li>
</ol>
<p>通过这种深度整合的智能服务模式，系统摆脱了传统"查找-匹配-回答"的机械模式，转而成为集"数据分析-系统联动-问题解决"为一体的智能业务助手，显著提升了问题一次性解决率和客户体验满意度。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="案例剖析企业文档智能创作系统">案例剖析：企业文档智能创作系统<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E6%A1%88%E4%BE%8B%E5%89%96%E6%9E%90%E4%BC%81%E4%B8%9A%E6%96%87%E6%A1%A3%E6%99%BA%E8%83%BD%E5%88%9B%E4%BD%9C%E7%B3%BB%E7%BB%9F" class="hash-link" aria-label="案例剖析：企业文档智能创作系统的直接链接" title="案例剖析：企业文档智能创作系统的直接链接">​</a></h3>
<p>在企业内容生产和知识沉淀领域，我们通过模型上下文协议构建了一套革新性的智能文档创作平台，彻底改变了传统企业文档生产的效率瓶颈：</p>
<ol>
<li>智能任务启动：业务人员只需提出核心需求（如"创建新产品技术白皮书"），系统立即理解任务性质与要求</li>
<li>自动资源整合：协议层自主激活并调用分散在企业各系统的相关资源，包括产品技术参数库、行业标准数据库、过往类似文档模板等</li>
<li>企业标准自适应：根据公司特定的文档规范和品牌调性，智能生成符合企业风格的高质量初稿</li>
<li>协同审阅机制：提供直观的内容比对与修订建议，支持专家与AI系统间的高效互动修改</li>
<li>知识闭环管理：一旦文档定稿，系统自动将新生成的知识点反向更新到企业知识库，实现知识资产的动态积累</li>
</ol>
<p>这一智能文档创作系统不仅大幅缩短了专业文档的产出周期（平均节省65%的制作时间），还显著提升了内容质量的一致性和专业性，同时解决了企业知识资产"孤岛化"和"陈旧化"的长期难题，让知识创作与沉淀形成良性循环。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="协议价值构建企业ai能力的新基础设施">协议价值：构建企业AI能力的新基础设施<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E5%8D%8F%E8%AE%AE%E4%BB%B7%E5%80%BC%E6%9E%84%E5%BB%BA%E4%BC%81%E4%B8%9Aai%E8%83%BD%E5%8A%9B%E7%9A%84%E6%96%B0%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD" class="hash-link" aria-label="协议价值：构建企业AI能力的新基础设施的直接链接" title="协议价值：构建企业AI能力的新基础设施的直接链接">​</a></h2>
<p>作为深耕企业智能化服务领域的技术团队，我们通过长期服务客服中心、知识管理体系和政企服务平台的实践经验，对模型上下文协议的战略价值有着深刻理解：</p>
<ul>
<li>服务智能化升级路径：该协议将成为新一代智能服务平台的核心技术基础，使AI系统从简单的"对话回应者"进阶为全方位的"业务处理中心"</li>
<li>知识资产活化催化剂：通过该协议，静态沉睡的企业知识库将获得新生，转变为可被智能系统实时调用、理解和应用的"动态决策中枢"</li>
<li>开发效率倍增器：对技术团队而言，这套协议体系大幅降低了复杂系统整合的技术门槛，实现了不同功能模块的即插即用，就像搭建积木一样快速组装企业专属AI应用</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="技术解构模型上下文协议的架构设计">技术解构：模型上下文协议的架构设计<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%84%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1" class="hash-link" aria-label="技术解构：模型上下文协议的架构设计的直接链接" title="技术解构：模型上下文协议的架构设计的直接链接">​</a></h2>
<p>我们的协议实现架构基于五大核心功能模块，共同构成了一套完整的智能处理生态：</p>
<ol>
<li><strong>语义理解引擎</strong>：采用多层次语义分析技术，能够精确解析用户表达背后的真实意图和潜在需求，实现对隐含信息的准确捕捉</li>
<li><strong>智能知识网络</strong>：整合向量检索、语义匹配和结构化查询等多种先进技术，实现对企业异构知识资源的统一管理与精准调用</li>
<li><strong>系统互联框架</strong>：提供标准化的系统调用接口与安全验证机制，支持动态扩展企业内外部工具能力，实现无缝系统协作</li>
<li><strong>情境持久化中心</strong>：创新性地实现对多轮会话历史的智能分析与关键信息提取，确保长对话过程中的逻辑连贯性与意图一致性</li>
<li><strong>自适应响应系统</strong>：基于综合信息处理结果，根据不同场景需求动态调整输出风格与专业度，生成既专业准确又自然流畅的回应</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="灵活部署多元化接入方案">灵活部署：多元化接入方案<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E7%81%B5%E6%B4%BB%E9%83%A8%E7%BD%B2%E5%A4%9A%E5%85%83%E5%8C%96%E6%8E%A5%E5%85%A5%E6%96%B9%E6%A1%88" class="hash-link" aria-label="灵活部署：多元化接入方案的直接链接" title="灵活部署：多元化接入方案的直接链接">​</a></h2>
<p>为满足不同企业的技术环境与集成需求，我们的模型上下文协议支持多种灵活部署方式：</p>
<ul>
<li><strong>企业级API服务</strong>：提供高性能、高可用的REST接口，支持标准HTTP调用，适合快速集成现有系统</li>
<li><strong>实时互动通道</strong>：基于WebSocket技术的双向通信机制，确保复杂业务场景下的即时响应能力</li>
<li><strong>多语言开发工具包</strong>：提供全面的SDK支持（覆盖Java、Python、Node.js等主流开发语言），降低企业二次开发成本</li>
<li><strong>行业解决方案模板</strong>：针对金融、零售、制造等垂直领域预构建的专属集成模板，加速行业特定场景落地</li>
</ul>
<p>如需获取详细的技术白皮书、接入文档或个性化咨询，欢迎与我们的解决方案团队联系。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="未来展望重塑企业智能化进程">未来展望：重塑企业智能化进程<a href="https://www.weiyuai.cn/docs/zh-CN/blog/mcp#%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B%E9%87%8D%E5%A1%91%E4%BC%81%E4%B8%9A%E6%99%BA%E8%83%BD%E5%8C%96%E8%BF%9B%E7%A8%8B" class="hash-link" aria-label="未来展望：重塑企业智能化进程的直接链接" title="未来展望：重塑企业智能化进程的直接链接">​</a></h2>
<p>模型上下文协议正逐步成为企业数字化转型中不可或缺的战略性技术底座。我们团队正在持续探索将这一协议体系与新一代智能客服平台、企业知识中台进行更深度的融合，致力于帮助各类组织充分释放"大模型+业务系统"的协同潜能。</p>
<p>这不仅仅是技术的演进，更是企业服务理念的革新。通过建立AI与业务系统间的无缝桥接，我们正在共同开创一个智能系统真正理解业务、主动解决问题的新时代。</p>
<p>期待与各行业伙伴携手，共同书写企业智能化的崭新篇章。</p>]]></content:encoded>
            <category>Developer</category>
            <category>Bytedesk</category>
            <category>AI</category>
            <category>Qwen3</category>
            <category>LLM</category>
        </item>
        <item>
            <title><![CDATA[微语多模态]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/multimodel</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/multimodel</guid>
            <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[微语多模态系统是一套先进的智能内容理解与生成解决方案，支持多种模态数据的分析、处理和转换，包括文本、图像、表格等多种数据形式的协同理解与处理。该系统可以实现跨模态的信息理解与生成，为用户提供更为丰富、精准的智能交互体验。]]></description>
            <content:encoded><![CDATA[<p>微语多模态系统是一套先进的智能内容理解与生成解决方案，支持多种模态数据的分析、处理和转换，包括文本、图像、表格等多种数据形式的协同理解与处理。该系统可以实现跨模态的信息理解与生成，为用户提供更为丰富、精准的智能交互体验。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="核心能力">核心能力<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B" class="hash-link" aria-label="核心能力的直接链接" title="核心能力的直接链接">​</a></h3>
<ul>
<li>
<p><strong>多模态文档理解</strong>：支持PDF、DOCX、PPTX格式文档的图片数据多模态内容理解，分为以下三类：</p>
<ul>
<li>自然图片：提供自然语言描述，精准捕捉图像内容要点</li>
<li>数据类图片（柱状图、折线图、雷达图等）：提供自然语言描述、图元信息（x轴y轴图例等含义）、数据变化趋势分析及CSV格式数据提取</li>
<li>流程类图片：提供自然语言描述、全流程名称解析及mermaid流程图语言转换</li>
</ul>
</li>
<li>
<p><strong>带图回答功能优化</strong>：</p>
<ul>
<li>回答准确率显著提升</li>
<li>支持在回答中同时呈现图片与表格</li>
<li>单次回答最大支持图片返回数量从3提升至9</li>
</ul>
</li>
<li>
<p><strong>优化联网检索能力</strong>：</p>
<ul>
<li>联网检索效果全面提升</li>
<li>检索后的网页内容自动解析并存储</li>
<li>自动生成联网检索网页集合知识库</li>
<li>支持检索结果预览</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="技术特点">技术特点<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%8A%80%E6%9C%AF%E7%89%B9%E7%82%B9" class="hash-link" aria-label="技术特点的直接链接" title="技术特点的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="模态融合技术">模态融合技术<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E6%8A%80%E6%9C%AF" class="hash-link" aria-label="模态融合技术的直接链接" title="模态融合技术的直接链接">​</a></h3>
<p>采用先进的多模态表示学习和跨模态对齐技术，实现不同模态数据（文本、图像、表格等）之间的深度融合和互补理解，使系统能够全面把握多模态内容的语义信息。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="视觉理解能力">视觉理解能力<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B" class="hash-link" aria-label="视觉理解能力的直接链接" title="视觉理解能力的直接链接">​</a></h3>
<ul>
<li><strong>图像内容理解</strong>：能够准确识别和描述图像中的对象、场景、活动和关系</li>
<li><strong>图表数据提取</strong>：针对各类数据可视化图表，不仅能进行视觉解读，还能将其中的数值信息转换为结构化数据</li>
<li><strong>图像OCR能力</strong>：能够从图像中提取文字信息，并将其与图像内容进行语义关联</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="高级分析能力">高级分析能力<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E9%AB%98%E7%BA%A7%E5%88%86%E6%9E%90%E8%83%BD%E5%8A%9B" class="hash-link" aria-label="高级分析能力的直接链接" title="高级分析能力的直接链接">​</a></h3>
<ul>
<li><strong>多维度分析</strong>：能够从多个层面对文档内容进行理解，包括事实性信息提取、情感分析、意图识别等</li>
<li><strong>趋势洞察</strong>：对于数据类图表，能够自动归纳数据变化趋势，提供数据背后的见解</li>
<li><strong>结构化转换</strong>：将非结构化的视觉内容转换为结构化的文本描述或数据格式</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="应用场景">应用场景<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF" class="hash-link" aria-label="应用场景的直接链接" title="应用场景的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="智能客服">智能客服<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D" class="hash-link" aria-label="智能客服的直接链接" title="智能客服的直接链接">​</a></h3>
<ul>
<li><strong>文档智能问答</strong>：客服系统可基于多模态文档理解，针对包含图片、图表的复杂文档提供准确回答</li>
<li><strong>产品图片理解</strong>：自动解析产品图片信息，提取关键特性，辅助客服快速回应产品相关咨询</li>
<li><strong>数据可视化解读</strong>：帮助客服人员解读客户提供的各类数据图表，进行专业分析和回应</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="企业知识管理">企业知识管理<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E4%BC%81%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86" class="hash-link" aria-label="企业知识管理的直接链接" title="企业知识管理的直接链接">​</a></h3>
<ul>
<li><strong>多模态知识库构建</strong>：自动处理企业内部包含图文、图表的文档，建立结构化知识库</li>
<li><strong>图表数据挖掘</strong>：从企业报告中自动提取图表数据，进行历史对比和趋势分析</li>
<li><strong>流程图解析与执行</strong>：自动识别业务流程图，转换为可执行的流程定义</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="内容创作与编辑">内容创作与编辑<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%86%85%E5%AE%B9%E5%88%9B%E4%BD%9C%E4%B8%8E%E7%BC%96%E8%BE%91" class="hash-link" aria-label="内容创作与编辑的直接链接" title="内容创作与编辑的直接链接">​</a></h3>
<ul>
<li><strong>智能内容丰富</strong>：根据文本描述自动推荐或生成相关图片、图表</li>
<li><strong>数据图表解读与润色</strong>：自动为数据图表生成专业解读文本，提升内容质量</li>
<li><strong>多模态内容转换</strong>：在保持语义一致的前提下，实现不同表达形式间的转换</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="性能与指标">性能与指标<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%80%A7%E8%83%BD%E4%B8%8E%E6%8C%87%E6%A0%87" class="hash-link" aria-label="性能与指标的直接链接" title="性能与指标的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="准确性">准确性<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%87%86%E7%A1%AE%E6%80%A7" class="hash-link" aria-label="准确性的直接链接" title="准确性的直接链接">​</a></h3>
<ul>
<li>自然图片描述准确率：&gt;95%</li>
<li>数据图表解析准确率：&gt;92%</li>
<li>流程图转换准确率：&gt;90%</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="处理能力">处理能力<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%A4%84%E7%90%86%E8%83%BD%E5%8A%9B" class="hash-link" aria-label="处理能力的直接链接" title="处理能力的直接链接">​</a></h3>
<ul>
<li>单次处理文档大小上限：50MB</li>
<li>图像识别分辨率支持：最高4K</li>
<li>单次最大处理图片数量：50张</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="响应速度">响应速度<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%93%8D%E5%BA%94%E9%80%9F%E5%BA%A6" class="hash-link" aria-label="响应速度的直接链接" title="响应速度的直接链接">​</a></h3>
<ul>
<li>单张图片分析平均响应时间：小于1秒</li>
<li>复杂文档处理平均响应时间：小于5秒/MB</li>
<li>联网检索与分析响应时间：小于3秒</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="最佳实践">最佳实践<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5" class="hash-link" aria-label="最佳实践的直接链接" title="最佳实践的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="文档处理优化">文档处理优化<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%BC%98%E5%8C%96" class="hash-link" aria-label="文档处理优化的直接链接" title="文档处理优化的直接链接">​</a></h3>
<ul>
<li>将大型文档分块处理，避免超出单次处理限制</li>
<li>预先定义关注的图表或图像类型，提高分析精准度</li>
<li>对于重复性强的文档，考虑建立专用模板提升识别效率</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="多模态应用设计">多模态应用设计<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1" class="hash-link" aria-label="多模态应用设计的直接链接" title="多模态应用设计的直接链接">​</a></h3>
<ul>
<li>结合多种模态输入设计交互流程，提供更自然的用户体验</li>
<li>针对不同行业场景，定制专属的视觉理解模型</li>
<li>利用联网检索功能增强回答的时效性和信息广度</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="性能调优">性能调优<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98" class="hash-link" aria-label="性能调优的直接链接" title="性能调优的直接链接">​</a></h3>
<ul>
<li>针对高频查询场景，建立结果缓存机制</li>
<li>对大型图片进行预处理压缩，提高处理速度</li>
<li>设置合理的并发请求限制，避免系统过载</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="常见问题">常见问题<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98" class="hash-link" aria-label="常见问题的直接链接" title="常见问题的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="q1-多模态系统支持哪些语言">Q1: 多模态系统支持哪些语言？<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#q1-%E5%A4%9A%E6%A8%A1%E6%80%81%E7%B3%BB%E7%BB%9F%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E8%AF%AD%E8%A8%80" class="hash-link" aria-label="Q1: 多模态系统支持哪些语言？的直接链接" title="Q1: 多模态系统支持哪些语言？的直接链接">​</a></h3>
<p>目前支持中文、英文、日文、韩文等20种主流语言的文本理解与生成，图像内容识别支持全球通用物体与场景。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="q2-如何提高图表数据提取的准确率">Q2: 如何提高图表数据提取的准确率？<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#q2-%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%9B%BE%E8%A1%A8%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87" class="hash-link" aria-label="Q2: 如何提高图表数据提取的准确率？的直接链接" title="Q2: 如何提高图表数据提取的准确率？的直接链接">​</a></h3>
<ul>
<li>确保图表图像清晰度足够高</li>
<li>避免过于复杂的图表设计和叠加</li>
<li>对于关键数据图表，可使用"精确模式"参数进行处理</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="q3-联网检索功能的数据来源有哪些">Q3: 联网检索功能的数据来源有哪些？<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#q3-%E8%81%94%E7%BD%91%E6%A3%80%E7%B4%A2%E5%8A%9F%E8%83%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E6%9C%89%E5%93%AA%E4%BA%9B" class="hash-link" aria-label="Q3: 联网检索功能的数据来源有哪些？的直接链接" title="Q3: 联网检索功能的数据来源有哪些？的直接链接">​</a></h3>
<p>系统集成了多种权威信息源，包括公开网络资源、学术数据库、行业报告等，保证信息的准确性和时效性。同时，系统会对检索到的信息进行可靠性评估和事实核验。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="资源与支持">资源与支持<a href="https://www.weiyuai.cn/docs/zh-CN/blog/multimodel#%E8%B5%84%E6%BA%90%E4%B8%8E%E6%94%AF%E6%8C%81" class="hash-link" aria-label="资源与支持的直接链接" title="资源与支持的直接链接">​</a></h2>
<ul>
<li><a href="https://help.aliyun.com/zh/model-studio/user-guide/multimodal/?spm=a2c4g.11186623.help-menu-2400256.d_0_2.66597ef572UZll" target="_blank" rel="noopener noreferrer">阿里云多模态</a></li>
</ul>]]></content:encoded>
            <category>Developer</category>
            <category>Bytedesk</category>
            <category>AI</category>
            <category>Qwen3</category>
            <category>LLM</category>
        </item>
        <item>
            <title><![CDATA[微语对接大模型Qwen3指南]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/qwen3</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/qwen3</guid>
            <pubDate>Wed, 30 Apr 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[在本篇博客中，我们将介绍如何将微语客服系统对接通义千问Qwen3大模型，使您的客服系统拥有强大的AI能力。通过这个集成，您可以为用户提供更智能、更高效的自动化客服体验。]]></description>
            <content:encoded><![CDATA[<p>在本篇博客中，我们将介绍如何将微语客服系统对接通义千问Qwen3大模型，使您的客服系统拥有强大的AI能力。通过这个集成，您可以为用户提供更智能、更高效的自动化客服体验。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="qwen3大模型介绍">Qwen3大模型介绍<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#qwen3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D" class="hash-link" aria-label="Qwen3大模型介绍的直接链接" title="Qwen3大模型介绍的直接链接">​</a></h2>
<p>通义千问Qwen3是阿里云推出的大型语言模型，具有强大的理解能力和生成能力。Qwen3系列模型在多轮对话、文本生成、问答解析等方面表现出色，非常适合客服场景应用。</p>
<p>Qwen3是千问系列大语言模型的最新一代，提供了全面的稠密模型和混合专家模型（Mixture-of-Experts，MoE）。您可以访问<a href="https://ollama.com/library/qwen3" target="_blank" rel="noopener noreferrer">Ollama官方库</a>获取更多详细信息。</p>
<p>目前Qwen3系列提供多种不同参数规模的模型版本，以适应不同的应用场景和硬件环境：</p>
<ul>
<li>Qwen3-tools: 针对工具使用进行特别优化的版本</li>
<li>Qwen3-0.6b: 超轻量版本，适合资源受限场景</li>
<li>Qwen3-1.8b: 轻量级模型，平衡性能和资源消耗</li>
<li>Qwen3-4b: 中小型模型，提供更好的理解力</li>
<li>Qwen3-8b: 中型模型，具有较强的推理能力</li>
<li>Qwen3-14b: 较大模型，提供优秀的理解和生成能力</li>
<li>Qwen3-30b: 大型模型，适合复杂任务处理</li>
<li>Qwen3-32b: 高性能大模型，强大的多任务能力</li>
<li>Qwen3-234b: 超大规模模型，顶级性能表现</li>
</ul>
<p>在本指南中，我们将使用Qwen3-4b版本进行演示，这是一个非常平衡的选择，既能提供良好的对话质量，又不会对普通设备造成过大负担。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="一ollama安装qwen3">一、Ollama安装Qwen3<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#%E4%B8%80ollama%E5%AE%89%E8%A3%85qwen3" class="hash-link" aria-label="一、Ollama安装Qwen3的直接链接" title="一、Ollama安装Qwen3的直接链接">​</a></h2>
<p><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer">Ollama</a>是一个开源的大模型运行框架，可以在本地部署运行多种大型语言模型，包括Qwen3。下面是安装和配置步骤：</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="1-安装ollama">1. 安装Ollama<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#1-%E5%AE%89%E8%A3%85ollama" class="hash-link" aria-label="1. 安装Ollama的直接链接" title="1. 安装Ollama的直接链接">​</a></h3>
<p>根据您的操作系统，选择相应的安装方法：</p>
<p><strong>MacOS</strong>:</p>
<div class="language-bash codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-bash codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-fsSL</span><span class="token plain"> https://ollama.ai/install.sh </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">sh</span><br></span></code></pre></div></div>
<p><strong>Linux</strong>:</p>
<div class="language-bash codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-bash codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-fsSL</span><span class="token plain"> https://ollama.ai/install.sh </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">sh</span><br></span></code></pre></div></div>
<p><strong>Windows</strong>:
从<a href="https://ollama.ai/download" target="_blank" rel="noopener noreferrer">Ollama官网</a>下载并安装Windows版本。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="2-拉取qwen3模型">2. 拉取Qwen3模型<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#2-%E6%8B%89%E5%8F%96qwen3%E6%A8%A1%E5%9E%8B" class="hash-link" aria-label="2. 拉取Qwen3模型的直接链接" title="2. 拉取Qwen3模型的直接链接">​</a></h3>
<p>安装完成后，通过命令行拉取Qwen3模型：</p>
<div class="language-bash codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-bash codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 拉取Qwen3 4b模型</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ollama pull qwen3:4b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 如果需要更大参数的模型，也可以选择其他版本</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ollama pull qwen3:8b</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ollama pull qwen3:14b</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="3-验证模型安装">3. 验证模型安装<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#3-%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E5%AE%89%E8%A3%85" class="hash-link" aria-label="3. 验证模型安装的直接链接" title="3. 验证模型安装的直接链接">​</a></h3>
<p>通过以下命令验证Qwen3模型是否安装成功：</p>
<div class="language-bash codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-bash codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token plain">ollama list</span><br></span></code></pre></div></div>
<p>您应该能看到已下载的qwen3模型列表。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="4-启动ollama服务">4. 启动Ollama服务<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#4-%E5%90%AF%E5%8A%A8ollama%E6%9C%8D%E5%8A%A1" class="hash-link" aria-label="4. 启动Ollama服务的直接链接" title="4. 启动Ollama服务的直接链接">​</a></h3>
<p>确保Ollama服务正在运行：</p>
<div class="language-bash codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-bash codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 在某些系统上，安装后会自动启动服务</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 如果没有自动启动，请使用以下命令</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ollama serve</span><br></span></code></pre></div></div>
<p>默认情况下，Ollama服务会在<code>http://localhost:11434</code>端口运行。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="二在微语管理后台设置qwen3对话模型">二、在微语管理后台设置Qwen3对话模型<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#%E4%BA%8C%E5%9C%A8%E5%BE%AE%E8%AF%AD%E7%AE%A1%E7%90%86%E5%90%8E%E5%8F%B0%E8%AE%BE%E7%BD%AEqwen3%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B" class="hash-link" aria-label="二、在微语管理后台设置Qwen3对话模型的直接链接" title="二、在微语管理后台设置Qwen3对话模型的直接链接">​</a></h2>
<p>完成Ollama和Qwen3模型的安装后，我们需要在微语管理后台进行配置：</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="1-登录微语管理后台">1. 登录微语管理后台<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#1-%E7%99%BB%E5%BD%95%E5%BE%AE%E8%AF%AD%E7%AE%A1%E7%90%86%E5%90%8E%E5%8F%B0" class="hash-link" aria-label="1. 登录微语管理后台的直接链接" title="1. 登录微语管理后台的直接链接">​</a></h3>
<p>访问您的微语管理后台，输入账号和密码登录系统。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="2-导航到ai设置">2. 导航到AI设置<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#2-%E5%AF%BC%E8%88%AA%E5%88%B0ai%E8%AE%BE%E7%BD%AE" class="hash-link" aria-label="2. 导航到AI设置的直接链接" title="2. 导航到AI设置的直接链接">​</a></h3>
<p>在左侧导航栏中，找到并点击"AI助手"-&gt;"机器人"选项。</p>
<p><img decoding="async" loading="lazy" alt="导航到AI设置" src="https://www.weiyuai.cn/docs/zh-CN/assets/images/qwen3_1-35b801bc6ec7a2e3840fd179f626456c.png" width="3196" height="1748" class="img_tUaM">
<em>图1：导航到AI设置</em></p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="3-切换qwen3模型配置">3. 切换Qwen3模型配置<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#3-%E5%88%87%E6%8D%A2qwen3%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE" class="hash-link" aria-label="3. 切换Qwen3模型配置的直接链接" title="3. 切换Qwen3模型配置的直接链接">​</a></h3>
<p>在AI设置页面中：</p>
<p><img decoding="async" loading="lazy" alt="切换Qwen3模型配置" src="https://www.weiyuai.cn/docs/zh-CN/assets/images/qwen3_2-b50733fadab34e51db1a4d7d7c1f53f2.png" width="3202" height="1746" class="img_tUaM">
<em>图2：切换Qwen3模型配置</em></p>
<ol>
<li>点击"AI模型选择"按钮</li>
<li>选择模型类型为"Ollama-&gt;Qwen3"</li>
<li>确认无误后，点击"确定"按钮</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="三开始使用qwen3进行智能对话">三、开始使用Qwen3进行智能对话<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#%E4%B8%89%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8qwen3%E8%BF%9B%E8%A1%8C%E6%99%BA%E8%83%BD%E5%AF%B9%E8%AF%9D" class="hash-link" aria-label="三、开始使用Qwen3进行智能对话的直接链接" title="三、开始使用Qwen3进行智能对话的直接链接">​</a></h2>
<p>配置完成后，您可以开始体验Qwen3赋能的智能客服功能：</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="1-创建知识库可选">1. 创建知识库（可选）<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#1-%E5%88%9B%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8F%AF%E9%80%89" class="hash-link" aria-label="1. 创建知识库（可选）的直接链接" title="1. 创建知识库（可选）的直接链接">​</a></h3>
<p>为了让AI回答更加准确，您可以创建和维护特定领域的知识库：</p>
<ol>
<li>导航到"知识库"或"AI训练"模块</li>
<li>点击"新建知识库"，输入名称和描述</li>
<li>上传文档或手动添加Q&amp;A对，丰富AI的专业知识</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="2-测试对话效果">2. 测试对话效果<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#2-%E6%B5%8B%E8%AF%95%E5%AF%B9%E8%AF%9D%E6%95%88%E6%9E%9C" class="hash-link" aria-label="2. 测试对话效果的直接链接" title="2. 测试对话效果的直接链接">​</a></h3>
<p>您可以通过以下方式测试Qwen3的对话能力：</p>
<ol>
<li>在管理后台的"对话测试"功能中，输入问题进行测试</li>
<li>通过客服端应用，模拟用户提问，验证AI回复效果</li>
<li>通过访客端，体验实际用户视角下的AI交互</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="3-对话效果展示">3. 对话效果展示<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#3-%E5%AF%B9%E8%AF%9D%E6%95%88%E6%9E%9C%E5%B1%95%E7%A4%BA" class="hash-link" aria-label="3. 对话效果展示的直接链接" title="3. 对话效果展示的直接链接">​</a></h3>
<p>以下是一些使用Qwen3进行智能对话的演示截图：</p>
<p><img decoding="async" loading="lazy" alt="Qwen3对话示例" src="https://www.weiyuai.cn/docs/zh-CN/assets/images/qwen3_3-8ed4ac99e01c12ef0c7a1b457d0e7096.png" width="3206" height="1534" class="img_tUaM">
<em>图3：Qwen3能够根据上下文提供连贯的多轮对话</em></p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="四优化和调整">四、优化和调整<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#%E5%9B%9B%E4%BC%98%E5%8C%96%E5%92%8C%E8%B0%83%E6%95%B4" class="hash-link" aria-label="四、优化和调整的直接链接" title="四、优化和调整的直接链接">​</a></h2>
<p>为了获得最佳的Qwen3对话效果，您可以进行以下优化：</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="1-调整模型参数">1. 调整模型参数<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#1-%E8%B0%83%E6%95%B4%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0" class="hash-link" aria-label="1. 调整模型参数的直接链接" title="1. 调整模型参数的直接链接">​</a></h3>
<p>根据实际需求调整模型参数，如温度值、最大token数等，以平衡回答的创造性和精确性。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="2-优化系统提示词">2. 优化系统提示词<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#2-%E4%BC%98%E5%8C%96%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D" class="hash-link" aria-label="2. 优化系统提示词的直接链接" title="2. 优化系统提示词的直接链接">​</a></h3>
<p>系统提示词对AI的行为有重要影响，您可以根据业务场景定制专业的提示词，引导AI表现出理想的对话风格。</p>
<h3 class="anchor anchorWithStickyNavbar_FOGJ" id="3-结合人工审核">3. 结合人工审核<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#3-%E7%BB%93%E5%90%88%E4%BA%BA%E5%B7%A5%E5%AE%A1%E6%A0%B8" class="hash-link" aria-label="3. 结合人工审核的直接链接" title="3. 结合人工审核的直接链接">​</a></h3>
<p>设置人工干预机制，对AI无法准确回答的问题进行人工接管，并将这些案例记录下来用于进一步训练和优化。</p>
<h2 class="anchor anchorWithStickyNavbar_FOGJ" id="总结">总结<a href="https://www.weiyuai.cn/docs/zh-CN/blog/qwen3#%E6%80%BB%E7%BB%93" class="hash-link" aria-label="总结的直接链接" title="总结的直接链接">​</a></h2>
<p>通过将微语客服系统与通义千问Qwen3大模型对接，您可以显著提升客服自动化水平和用户体验。本指南详细介绍了从安装Ollama、配置Qwen3模型到实际应用的完整流程。</p>
<p>随着您不断优化提示词和积累领域知识库，AI助手的表现会越来越符合您的业务需求，为客户提供更加专业、高效的服务体验。</p>
<p>如有任何问题或需要进一步的技术支持，请随时联系我们的技术团队。</p>
<hr>
<p>希望本指南对您成功部署和使用微语+Qwen3智能客服系统有所帮助！</p>]]></content:encoded>
            <category>Developer</category>
            <category>Bytedesk</category>
            <category>AI</category>
            <category>Qwen3</category>
            <category>LLM</category>
        </item>
        <item>
            <title><![CDATA[扫码登录实现流程]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/scan-to-login</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/scan-to-login</guid>
            <pubDate>Tue, 08 Oct 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[- 桌面客户端生成唯一设备uid：deviceUid]]></description>
            <content:encoded><![CDATA[<ul>
<li>桌面客户端生成唯一设备uid：deviceUid</li>
<li>将此deviceUid发送给服务端，服务端返回随机码：randomCode</li>
<li>桌面客户端使用randomCode和deviceUid生成二维码</li>
<li>手机端扫描此二维码，获取到deviceUid，将deviceUid发送给服务端，服务端更新状态为已扫描SCANED</li>
<li>手机端点击确认登录，将手机号mobile和deviceUid发送给服务端，服务端保存手机号并更新状态为已登录CONFIRMED</li>
<li>桌面客户端通过轮询获取到手机号mobile和状态为已登录CONFIRMED，利用手机号和随机码randomCode，调用登录接口</li>
<li>如果桌面客户端拉取到的状态为EXPIRED，则需要重新拉取随机码randomCode，并重新生成二维码</li>
<li>登录成功，返回accessToken，桌面客户端将此accessToken保存到本地，跳转到首页</li>
</ul>
<p>扫码登录实现流程</p>]]></content:encoded>
            <category>Developer</category>
            <category>Bytedesk</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/welcome</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/welcome</guid>
            <pubDate>Thu, 26 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Docusaurus blogging features are powered by the blog plugin.]]></description>
            <content:encoded><![CDATA[<p><a href="https://docusaurus.io/docs/blog" target="_blank" rel="noopener noreferrer">Docusaurus blogging features</a> are powered by the <a href="https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog" target="_blank" rel="noopener noreferrer">blog plugin</a>.</p>
<p>Here are a few tips you might find useful.</p>
<p>Simply add Markdown files (or folders) to the <code>blog</code> directory.</p>
<p>Regular blog authors can be added to <code>authors.yml</code>.</p>
<p>The blog post date can be extracted from filenames, such as:</p>
<ul>
<li><code>2019-05-30-welcome.md</code></li>
<li><code>2019-05-30-welcome/index.md</code></li>
</ul>
<p>A blog post folder can be convenient to co-locate blog post images:</p>
<p><img decoding="async" loading="lazy" alt="Docusaurus Plushie" src="https://www.weiyuai.cn/docs/zh-CN/assets/images/docusaurus-plushie-banner-a60f7593abca1e3eef26a9afa244e4fb.jpeg" width="1500" height="500" class="img_tUaM"></p>
<p>The blog supports tags as well!</p>
<p><strong>And if you don't want a blog</strong>: just delete this directory, and use <code>blog: false</code> in your Docusaurus config.</p>]]></content:encoded>
            <category>Facebook</category>
            <category>Hello</category>
            <category>Docusaurus</category>
        </item>
        <item>
            <title><![CDATA[MDX Blog Post]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/mdx-blog-post</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/mdx-blog-post</guid>
            <pubDate>Sun, 01 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Blog posts support Docusaurus Markdown features, such as MDX.]]></description>
            <content:encoded><![CDATA[<p>Blog posts support <a href="https://docusaurus.io/docs/markdown-features" target="_blank" rel="noopener noreferrer">Docusaurus Markdown features</a>, such as <a href="https://mdxjs.com/" target="_blank" rel="noopener noreferrer">MDX</a>.</p>
<div class="theme-admonition theme-admonition-tip admonition_VPQ_ alert alert--success"><div class="admonitionHeading_tvin"><span class="admonitionIcon_Yt4N"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_kQJn"><p>Use the power of React to create interactive blog posts.</p></div></div>
<!-- -->
<p>For example, use JSX to create an interactive button:</p>
<div class="language-js codeBlockContainer__5Rl theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_wpOC"><pre tabindex="0" class="prism-code language-js codeBlock_UNI2 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_tunX"><span class="token-line" style="color:#393A34"><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">button onClick</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token arrow operator" style="color:#393A34">=&gt;</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">alert</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">'button clicked!'</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token maybe-class-name">Click</span><span class="token plain"> me</span><span class="token operator" style="color:#393A34">!</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">button</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<button>Click me!</button>]]></content:encoded>
            <category>Docusaurus</category>
        </item>
        <item>
            <title><![CDATA[Long Blog Post]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/long-blog-post</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/long-blog-post</guid>
            <pubDate>Wed, 29 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[This is the summary of a very long blog post,]]></description>
            <content:encoded><![CDATA[<p>This is the summary of a very long blog post,</p>
<p>Use a <code>&lt;!--</code> <code>truncate</code> <code>--&gt;</code> comment to limit blog post size in the list view.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>Hello</category>
            <category>Docusaurus</category>
        </item>
        <item>
            <title><![CDATA[First Blog Post]]></title>
            <link>https://www.weiyuai.cn/docs/zh-CN/blog/first-blog-post</link>
            <guid>https://www.weiyuai.cn/docs/zh-CN/blog/first-blog-post</guid>
            <pubDate>Tue, 28 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Lorem ipsum dolor sit amet...]]></description>
            <content:encoded><![CDATA[<p>Lorem ipsum dolor sit amet...</p>
<p>...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>Hola</category>
            <category>Docusaurus</category>
        </item>
    </channel>
</rss>